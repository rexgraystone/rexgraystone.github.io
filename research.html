<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Research | Raghav Nanjappan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<div class="site-wrapper">
  <header>
    <div class="header-inner">
      <div class="brand">Raghav Nanjappan</div>
      <nav>
        <a href="index.html" class="nav-link">Home</a>
        <a href="about.html" class="nav-link">About</a>
        <a href="research.html" class="nav-link active">Research</a>
        <a href="projects.html" class="nav-link">Projects</a>
        <a href="cv.html" class="nav-link">CV</a>
        <a href="contact.html" class="nav-link">Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <div class="main-inner">
      <section class="section">
        <h1 class="section-title">Research</h1>
        <p class="section-subtitle">
          Publications and ongoing directions in VR, HCI, and intelligent systems.
        </p>

        <div class="section">
          <h2 class="section-title" style="font-size:1.2rem;">Publications</h2>
          <div class="card-list">
            <article class="card">
              <h3>NeuroTransformer: Transformer Model for Motor Imagery Classification</h3>
              <div class="card-meta">
                Raghav Nanjappan, N. Vinutha, and V. Jayavrinda. 2025. Neurotransformer: Transformer model for motor imagery classification. Lecture Notes in Networks and Systems 1239 (June 2025), 327-336. DOI: <a href="http://dx.doi.org/10.1007/978-981-96-1188-1_24" target="_blank">http://dx.doi.org/10.1007/978-981-96-1188-1_24</a>
              </div>
              <p class="muted">
                Motor Imagery Classification is a pivotal task, facilitating direct communication between the human brain and external devices. Traditional methodologies often rely on manual feature engineering and basic classifiers, posing limitations in capturing intricate patterns within brain signals. Addressing this challenge, we propose a pioneering transformer-based framework tailored to motor imagery classification in BCIs. Our model capitalizes on the inherent self-attention mechanism of transformers to autonomously discern hierarchical representations from EEG sig-nals, thereby adeptly capturing both spatial and temporal dependencies. Through rigorous experimentation on publicly available EEG datasets such as the BCI Competition IV 2a dataset designed for motor imagery tasks, we showcase the efficacy of NeuroTransformer architecture with an accuracy of 86.2%, Sensitivity of 83.5% and Precision of 85.4%. Additionally, incorporating Principal Component Analysis with NeuroTransformer yields an accuracy of 86.7%, Sensitivity of 82.8%, and Precision of 86.1%. In the future, we focus on handling the problems associated with inter and intra-subject variability.
              </p>
              <div class="card-links">
                <a href="#" target="_blank">PDF</a> ·
                <a href="#" target="_blank">Publisher</a> ·
                <a href="#" target="_blank">BibTeX</a>
              </div>
            </article>

            <article class="card">
              <h3>Empowering Speech-Impaired Individuals: EEG-Driven Cognitive Expression Translated into Speech</h3>
              <div class="card-meta">
                Jayavrinda Vrindavanam, Roshni M. Balakrishnan, Raghav Nanjappan, Gaurav Kamath. Empowering Speech-Impaired Individuals: EEG-Driven Cognitive Expression Translated into Speech. International Journal of Computer Applications. 185, 28 (Aug 2023), 43-46. DOI: <a href="https://doi.org/10.5120/ijca2023923034" target="_blank">10.5120/ijca2023923034</a>
              </div>
              <p class="muted">
                This work explores the development of a brain-computer interface system that translates EEG signals into speech output, enabling communication for speech-impaired individuals through cognitive expression.
              </p>
              <div class="card-links">
                <a href="#" target="_blank">PDF</a> ·
                <a href="#" target="_blank">Publisher</a> ·
                <a href="#" target="_blank">BibTeX</a>
              </div>
            </article>

            <!-- Add more publication cards here as they are accepted. -->
          </div>
        </div>

        <div class="section">
          <h2 class="section-title" style="font-size:1.2rem; margin-top:2rem;">Current research themes</h2>
          <div class="card-list">
            <article class="card">
              <h3>VR Locomotion &amp; Cybersickness</h3>
              <p class="muted">
                Studying how different locomotion strategies and camera motion parameters
                influence cybersickness and comfort in VR, with the goal of deriving 
                design guidelines and adaptive control strategies.
              </p>
            </article>
            <article class="card">
              <h3>Multisensory Conflicts in Immersive Environments</h3>
              <p class="muted">
                Investigating how conflicts between visual, vestibular, and proprioceptive cues 
                impact balance, presence, and task performance, and how these conflicts can be 
                mitigated or used deliberately in interaction design.
              </p>
            </article>
            <article class="card">
              <h3>Human-AI Interaction in VR Systems</h3>
              <p class="muted">
                Exploring user trust, adaptation, and mental models when interacting with 
                intelligent agents and adaptive systems embedded in virtual reality environments.
              </p>
            </article>
          </div>
        </div>
      </section>
    </div>
  </main>

  <footer>
    © <span id="year"></span> Raghav Nanjappan · raghavnanjappan.com
  </footer>
</div>
<script>
  document.getElementById('year').textContent = new Date().getFullYear();
</script>
</body>
</html>
