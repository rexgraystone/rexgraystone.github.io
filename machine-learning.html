<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Machine Learning Projects | Raghav Nanjappan</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="icon" type="image/jpeg" href="imgs/Favicon.jpg" />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<div class="site-wrapper">
  <header>
    <div class="header-inner">
      <div class="brand">Raghav Nanjappan</div>
      <nav>
        <a href="index.html" class="nav-link">Home</a>
        <a href="about.html" class="nav-link">About</a>
        <a href="research.html" class="nav-link">Research</a>
        <a href="projects.html" class="nav-link">Projects</a>
        <a href="cv.html" class="nav-link">CV</a>
        <a href="contact.html" class="nav-link">Contact</a>
      </nav>
    </div>
  </header>

  <main>
    <div class="main-inner">
      <section class="section">
        <h1 class="section-title">Machine Learning Projects</h1>
        <p class="section-subtitle">
          Deep learning and machine learning projects in computer vision, natural language processing, and data science.
        </p>

        <div class="section">
          <h2 class="section-title" style="font-size:1.2rem;">Computer Vision</h2>
          <div class="card-list">
            <article class="card">
              <h3>FaceAuth</h3>
              <div class="card-meta">Deep Learning · ResNet50 · Image Classification · September 2023</div>
              <p class="muted">
                Trained a deep learning model that classifies real and AI generated images of faces. The dataset used to train the model can be found <a href="https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces" target="_blank">here</a>. Utilized ResNet50 as the base layer and added 2 dense layers to the model. Calculated the loss with categorical cross-entropy and optimized the model with Adam optimizer.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/faceauth" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>PneumoGuard</h3>
              <div class="card-meta">Deep Learning · ResNet152 · Medical Imaging · September 2023</div>
              <p class="muted">
                Trained a deep learning model that classifies pneumonia from lung CT scans. The dataset used to train the model can be found <a href="https://data.mendeley.com/datasets/rscbjbr9sj/3" target="_blank">here</a>. Generated masks of all the 5233 images present in the dataset by applying smoothing and Roberts cross operator. Utilized ResNet152 as the base layer and added 2 dense layers to the model. Calculated the loss with binary cross-entropy and optimized the model with Adam optimizer.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/pneumoguard" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>SoleSleuth</h3>
              <div class="card-meta">Deep Learning · ResNet152 · TensorFlow · May 2023</div>
              <p class="muted">
                Trained a deep learning model using Tensorflow based on the ResNet152, that classifies scans of shoe imprints to their respective sizes. The dataset used to train the model can be found <a href="https://iastate.figshare.com/articles/figure/2D_Footwear_outsole_impressions/11624073/1" target="_blank">here</a>. The model was trained twice, once with the raw images and once with the masks of the images. The masked images were generated by applying smoothing and Roberts cross edge detector.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/solesleuth" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>DeepLung</h3>
              <div class="card-meta">Deep Learning · TensorFlow · Medical Imaging · May 2023</div>
              <p class="muted">
                Trained a deep learning model using Tensorflow, that classifies chest CT scans as cancerous or non-cancerous. The dataset used to train the model was obtained from <a href="https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images" target="_blank">Kaggle</a>. The model was trained twice, once with the raw images and once with the masks of the images. The masked images were generated by applying smoothing and Roberts cross edge detector.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/deeplung" target="_blank">GitHub</a>
              </div>
            </article>
          </div>
        </div>

        <div class="section">
          <h2 class="section-title" style="font-size:1.2rem; margin-top:2rem;">Natural Language Processing</h2>
          <div class="card-list">
            <article class="card">
              <h3>SarcastoScope</h3>
              <div class="card-meta">Deep Learning · LSTM · GRU · Word2Vec · May 2023</div>
              <p class="muted">
                Trained a deep learning model using a combination of LSTM and GRU layers, that classifies news headlines as sarcastic or non-sarcastic. The dataset, obtained from <a href="https://www.kaggle.com/datasets/rmisra/news-headlines-dataset-for-sarcasm-detection" target="_blank">Kaggle</a>, was preprocessed by removing the stopwords and tokenizing the headlines. The headlines were then converted to word vectors using the Word2Vec model. The activation function used in the hidden layers were 'tanh', while the output layer used 'sigmoid'.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/sarcastoscope" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>MovieMatch AI</h3>
              <div class="card-meta">Deep Learning · TensorFlow · NLTK · April 2023</div>
              <p class="muted">
                Built a movie recommendation system that recommends movies based on the user's preferences. The dataset used to train the model was obtained from <a href="https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata" target="_blank">Kaggle</a>. The dataset was cleaned and preprocessed using NLTK. The model was trained using the Word2Vec model. The activation function used in the hidden layers were 'tanh', while the output layer used 'sigmoid'.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/moviematch-ai" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>CineChat</h3>
              <div class="card-meta">Deep Learning · TensorFlow · NLTK · March 2023</div>
              <p class="muted">
                Trained a deep learning model using Tensorflow that responds to a sentence from a movie with a relevant quote from the same movie. The custom dataset was created by referring to the <a href="https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html" target="_blank">Cornell Movie-Dialogs Corpus</a>. The dataset was cleaned and preprocessed using NLTK.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/cinechat" target="_blank">GitHub</a>
              </div>
            </article>
          </div>
        </div>

        <div class="section">
          <h2 class="section-title" style="font-size:1.2rem; margin-top:2rem;">Data Science</h2>
          <div class="card-list">
            <article class="card">
              <h3>iChurn</h3>
              <div class="card-meta">Machine Learning · Classification · Neural Networks · May 2023</div>
              <p class="muted">
                Analyzed the performance of different classifiers for predicting customer churn. The dataset used to train the models was obtained from <a href="https://www.kaggle.com/datasets/blastchar/telco-customer-churn" target="_blank">Kaggle</a>. The dataset was also used to train a convolutional neural network.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/ichurn" target="_blank">GitHub</a>
              </div>
            </article>

            <article class="card">
              <h3>IPLay</h3>
              <div class="card-meta">Web Scraping · Machine Learning · Selenium · Beautiful Soup · April 2023</div>
              <p class="muted">
                Developed a web scraper that scrapes the IPL website for the tables of all previous seasons, using Selenium and Beautiful Soup. Trained multiple machine learning models that predicts the probability of a team in the Indian Premier League qualifying for the playoffs. The decision tree model performed with the highest accuracy.
              </p>
              <div class="card-links">
                <a href="https://github.com/rexgraystone/iplay" target="_blank">GitHub</a>
              </div>
            </article>
          </div>
        </div>
      </section>
    </div>
  </main>

  <footer>
    © <span id="year"></span> Raghav Nanjappan · raghavnanjappan.com
  </footer>
</div>
<script>
  document.getElementById('year').textContent = new Date().getFullYear();
</script>
</body>
</html>

